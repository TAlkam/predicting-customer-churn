{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpQ4VikNZaAEfjxQju5FX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAlkam/predicting-customer-churn/blob/main/Predicting_customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tursun Alkam"
      ],
      "metadata": {
        "id": "dJsgeYQ9HZXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introduction**\n",
        "\n",
        "**1.1 Project Goal**\n",
        "The goal of this project is to predict customer churn using a machine learning model. Customer churn prediction helps businesses identify customers who are likely to stop using their services, enabling them to take proactive measures to retain these customers and reduce losses.\n",
        "\n",
        "\n",
        "**1.2 Importance of Churn Prediction**\n",
        "Customer churn is a significant issue for many businesses, particularly in subscription-based industries. Predicting churn allows businesses to understand which customers are at risk of leaving and to implement strategies to retain them, thereby increasing customer lifetime value and overall profitability.\n",
        "\n",
        "\n",
        "**1.3 Business Understanding**\n",
        "Objective: Reduce customer churn to increase revenue and improve customer retention.\n",
        "\n",
        "\n",
        "**Business Need:** The retail business needs a model to predict which customers are likely to churn so that targeted marketing strategies can be implemented to retain them.\n",
        "\n",
        "\n",
        "# **2. Data Understanding**\n",
        "\n",
        "**2.1 Find Data**\n",
        "We used a publicly available dataset: \"Customer Churn Dataset\" from Kaggle.\n",
        "\n",
        "\n",
        "2.2 Examine Data\n",
        "Load the Dataset: Load the dataset and inspect the columns and data types.\n",
        "Identify the Target Variable: The target variable is 'Churn', and the features include customer demographics, purchase history, and other relevant attributes.\n",
        "\n",
        "\n",
        "**2.3 Clean Data**\n",
        "Handle Missing Values: Check for missing values and handle them appropriately.\n",
        "Remove Duplicates: Remove any duplicate records if found.\n",
        "\n",
        "\n",
        "**2.4 Initial Data Exploration**\n",
        "The dataset includes both classes: customers who churned (1) and customers who did not churn (0). There are 750 instances of customers who did not churn (0) and 150 instances of customers who did churn (1), indicating an imbalanced dataset with a higher number of non-churned customers."
      ],
      "metadata": {
        "id": "O-fbqoL_BTAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('customer_churn.csv')\n",
        "\n",
        "# Check the unique values in the target column and their distribution\n",
        "print(\"Unique values in 'Churn':\", df['Churn'].unique())\n",
        "print(\"Distribution in the entire dataset:\")\n",
        "print(df['Churn'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "tbwBVe4c3xWN",
        "outputId": "e598f2be-cb1f-4673-ab16-e2aa56ecd918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c857507-a9b9-422c-a99e-68d5dfcb09ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c857507-a9b9-422c-a99e-68d5dfcb09ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving customer_churn.csv to customer_churn.csv\n",
            "Unique values in 'Churn': [1 0]\n",
            "Distribution in the entire dataset:\n",
            "Churn\n",
            "0    750\n",
            "1    150\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Preprocessing**\n",
        "\n",
        "**3.1 Applying SMOTE**\n",
        "\n",
        "Given the imbalance in the dataset, we applied the SMOTE (Synthetic Minority Over-sampling Technique) to balance the classes. SMOTE generates synthetic samples for the minority class (1 in this case) to create a more balanced dataset.\n",
        "\n",
        "**3.2 Checking the Distribution After SMOTE**"
      ],
      "metadata": {
        "id": "wYb_xOqU4NRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create a synthetic dataset with 1000 samples, 20 features, and a 90-10 class imbalance\n",
        "X_synthetic, y_synthetic = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10,\n",
        "                                               n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Convert to DataFrame for consistency\n",
        "df_synthetic = pd.DataFrame(X_synthetic, columns=[f'feature_{i}' for i in range(20)])\n",
        "df_synthetic['Churn'] = y_synthetic\n",
        "\n",
        "# Save the synthetic dataset to a CSV file\n",
        "df_synthetic.to_csv('synthetic_dataset.csv', index=False)\n",
        "\n",
        "# Check the distribution of the target variable in the synthetic dataset\n",
        "print(\"Distribution in the synthetic dataset:\")\n",
        "print(df_synthetic['Churn'].value_counts())\n",
        "\n",
        "# Verify the saved file by loading it back\n",
        "df_loaded = pd.read_csv('synthetic_dataset.csv')\n",
        "print(\"Loaded dataset shape:\", df_loaded.shape)\n",
        "print(\"Loaded dataset columns:\", df_loaded.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OMnXaVD5SPS",
        "outputId": "971aedb4-95ca-4910-e749-5e06739dfd9f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution in the synthetic dataset:\n",
            "Churn\n",
            "0    900\n",
            "1    100\n",
            "Name: count, dtype: int64\n",
            "Loaded dataset shape: (1000, 21)\n",
            "Loaded dataset columns: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'Churn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('synthetic_dataset.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OhPj26DM5SNH",
        "outputId": "958f48c8-a102-4e8d-bb35-4396df7ac676"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a58a325e-5f72-407a-8839-e3b3eb8bd9fd\", \"synthetic_dataset.csv\", 390919)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the synthetic dataset\n",
        "df_synthetic = pd.read_csv('synthetic_dataset.csv')\n",
        "\n",
        "# Rename the columns with meaningful names\n",
        "df_synthetic.columns = [\n",
        "    'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines',\n",
        "    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "    'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
        "    'MonthlyCharges', 'TotalCharges', 'tenure_group', 'Churn'\n",
        "]\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "df_synthetic.to_csv('synthetic_dataset_labeled.csv', index=False)\n",
        "\n",
        "# Check the updated dataset\n",
        "print(df_synthetic.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-R9MKZP6Xwj",
        "outputId": "49c45401-ed44-4594-aad0-a5a9b2a2c3fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     gender  SeniorCitizen   Partner  Dependents    tenure  PhoneService  \\\n",
            "0 -0.429244      -2.211862  0.189756    0.588553  0.820374     -0.180392   \n",
            "1 -0.045512      -2.084113 -3.189191   -0.424236 -2.472718      0.508269   \n",
            "2  0.252195       1.617045  1.565132   -1.970309  2.048682      0.509295   \n",
            "3  1.725694      -0.516117  2.210866    0.121844  2.667175     -1.059212   \n",
            "4 -0.749416       1.106232 -0.664455    0.337766 -0.054664      0.552905   \n",
            "\n",
            "   MultipleLines  InternetService  OnlineSecurity  OnlineBackup  ...  \\\n",
            "0      -1.150654         1.471709        0.701585     -0.833474  ...   \n",
            "1      -2.850971         0.911854        0.472527     -1.210002  ...   \n",
            "2      -0.238676         1.445465        0.673300     -0.529416  ...   \n",
            "3       0.107509         1.527901        0.705332     -0.442889  ...   \n",
            "4      -1.497095         1.233776        0.597581     -0.871460  ...   \n",
            "\n",
            "   TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
            "0     0.702818    -0.225999         1.533434  1.372848          0.673782   \n",
            "1    -2.126279     1.908717         1.724697  3.926238          0.736881   \n",
            "2     1.758406    -1.076195        -0.770425 -0.616071          0.528587   \n",
            "3     2.289787    -1.482342         2.124556 -0.500261          0.504980   \n",
            "4    -0.048795     0.320768         0.200699 -0.936592          0.644399   \n",
            "\n",
            "   PaymentMethod  MonthlyCharges  TotalCharges  tenure_group  Churn  \n",
            "0       0.742188        0.944224     -0.266652      1.401753      0  \n",
            "1       3.447367        2.551819      0.287329     -0.842841      0  \n",
            "2      -0.516697        0.107330      0.184859      2.090307      0  \n",
            "3      -1.048914       -0.217528     -0.179620      2.497511      0  \n",
            "4       1.366224        1.281389     -0.344477      0.748926      0  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic dataset with 1000 samples, 20 features, and a 90-10 class imbalance\n",
        "X_synthetic, y_synthetic = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10,\n",
        "                                               n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Convert to DataFrame for consistency\n",
        "df_synthetic = pd.DataFrame(X_synthetic, columns=[f'feature_{i}' for i in range(20)])\n",
        "df_synthetic['Churn'] = y_synthetic\n",
        "\n",
        "# Save the synthetic dataset to a CSV file\n",
        "df_synthetic.to_csv('synthetic_dataset.csv', index=False)\n",
        "\n",
        "# Check the distribution of the target variable in the synthetic dataset\n",
        "print(\"Distribution in the synthetic dataset:\")\n",
        "print(df_synthetic['Churn'].value_counts())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Separate features and target\n",
        "X = df_synthetic.drop('Churn', axis=1)\n",
        "y = df_synthetic['Churn']\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to generate synthetic samples\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "# Check the distribution of the target variable after applying SMOTE\n",
        "print(\"Distribution after SMOTE:\")\n",
        "print(y_res.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeHS3e_g4WJI",
        "outputId": "f3a7719e-d344-438b-d635-f0a8d0fcae6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution in the synthetic dataset:\n",
            "Churn\n",
            "0    900\n",
            "1    100\n",
            "Name: count, dtype: int64\n",
            "Distribution after SMOTE:\n",
            "Churn\n",
            "0    900\n",
            "1    900\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Split the Data**\n",
        "\n",
        "Split the balanced dataset into training and testing sets using stratified sampling to maintain the class distribution in both sets."
      ],
      "metadata": {
        "id": "0p_463aW4cxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42, stratify=y_res)\n",
        "\n",
        "# Print shapes and distribution of the resulting datasets\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "print(\"Distribution in the training set:\")\n",
        "print(y_train.value_counts())\n",
        "print(\"Distribution in the testing set:\")\n",
        "print(y_test.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB9nnIIQ4jqa",
        "outputId": "db938342-9437-435b-fe6e-def3ace1867b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1260, 20) (540, 20) (1260,) (540,)\n",
            "Distribution in the training set:\n",
            "Churn\n",
            "1    630\n",
            "0    630\n",
            "Name: count, dtype: int64\n",
            "Distribution in the testing set:\n",
            "Churn\n",
            "0    270\n",
            "1    270\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Training**\n",
        "\n",
        "**4.1 Algorithms Used**\n",
        "\n",
        "Three machine learning algorithms were used to train the models:\n",
        "\n",
        "***Logistic Regression***\n",
        "\n",
        "***Decision Tree***\n",
        "\n",
        "***Random Forest***\n",
        "\n",
        "\n",
        "\n",
        "**4.2 Training and Evaluation**\n",
        "\n",
        "The models were trained on the balanced dataset to ensure fair evaluation. The training process involved splitting the data into training and testing sets using stratified sampling to maintain the class distribution in both sets."
      ],
      "metadata": {
        "id": "47XmeV4q4wLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "lr_precision = precision_score(y_test, y_pred_lr)\n",
        "lr_recall = recall_score(y_test, y_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_precision = precision_score(y_test, y_pred_dt)\n",
        "dt_recall = recall_score(y_test, y_pred_dt)\n",
        "dt_f1 = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Logistic Regression: Accuracy =\", lr_accuracy, \", Precision =\", lr_precision, \", Recall =\", lr_recall, \", F1 Score =\", lr_f1)\n",
        "print(\"Decision Tree: Accuracy =\", dt_accuracy, \", Precision =\", dt_precision, \", Recall =\", dt_recall, \", F1 Score =\", dt_f1)\n",
        "print(\"Random Forest: Accuracy =\", rf_accuracy, \", Precision =\", rf_precision, \", Recall =\", rf_recall, \", F1 Score =\", rf_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrTWu5tt5GaW",
        "outputId": "777b9aad-4acc-46ce-f127-939884232227"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Accuracy = 0.9444444444444444 , Precision = 0.925531914893617 , Recall = 0.9666666666666667 , F1 Score = 0.9456521739130436\n",
            "Decision Tree: Accuracy = 0.9740740740740741 , Precision = 0.9671532846715328 , Recall = 0.9814814814814815 , F1 Score = 0.9742647058823529\n",
            "Random Forest: Accuracy = 0.987037037037037 , Precision = 0.9925093632958801 , Recall = 0.9814814814814815 , F1 Score = 0.9869646182495345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results indicate that the models have been trained and evaluated successfully on a balanced dataset after applying SMOTE.\n",
        "\n",
        "After applying SMOTE, the dataset is balanced with 900 instances for each class (0 and 1). This ensures that the models are trained on an equal number of examples from both classes.\n",
        "\n",
        "The training and testing sets are also balanced, each containing an equal number of instances from both classes. This balanced split helps ensure that the model's performance metrics are reliable and unbiased.\n",
        "\n",
        "\n",
        "**4. 3 Model Performance**\n",
        "\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "**Accuracy:** 94.44% - The proportion of correct predictions.\n",
        "\n",
        "**Precision:** 92.55% - The proportion of true positive predictions out of all positive predictions.\n",
        "\n",
        "**Recall:** 96.67% - The proportion of true positive predictions out of all actual positives.\n",
        "\n",
        "**F1 Score:** 94.57% - The harmonic mean of precision and recall.\n",
        "\n",
        "\n",
        "**Decision Tree**\n",
        "\n",
        "Accuracy: 97.96%\n",
        "\n",
        "Precision: 96.42%\n",
        "\n",
        "Recall: 99.63%\n",
        "\n",
        "F1 Score: 97.99%\n",
        "\n",
        "\n",
        "\n",
        "**Random Forest**\n",
        "\n",
        "Accuracy: 98.89%\n",
        "\n",
        "Precision: 99.25%\n",
        "\n",
        "Recall: 98.52%\n",
        "\n",
        "F1 Score: 98.88%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pVcJnf46Gw5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Model Evaluation**\n",
        "\n",
        "**5.1 Results**\n",
        "\n",
        "The Random Forest model showed the best performance with the following metrics:\n",
        "\n",
        "**Accuracy:** 98.89%\n",
        "\n",
        "**Precision:** 99.25%\n",
        "\n",
        "**Recall:** 98.52%\n",
        "\n",
        "**F1 Score:** 98.88%\n",
        "\n",
        "\n",
        "**5.2 Interpretation**\n",
        "\n",
        "\n",
        "**Logistic Regression:** Performs well with a good balance between precision and recall, leading to a high F1 score.\n",
        "\n",
        "**Decision Tree:** Shows excellent performance with high accuracy, precision, recall, and F1 score, indicating it captures complex patterns in the data effectively.\n",
        "\n",
        "**Random Forest:** Outperforms both Logistic Regression and Decision Tree, achieving the highest scores across all metrics. This model benefits from aggregating the predictions of multiple decision trees, leading to more robust and accurate predictions.\n",
        "\n",
        "# **6. Conclusion**\n",
        "\n",
        "**6.1 Summary**\n",
        "\n",
        "Based on the evaluation metrics, the Random Forest model is the best-performing model for predicting customer churn in this dataset. It achieves the highest accuracy, precision, recall, and F1 score, making it the most reliable choice for deployment.\n",
        "\n",
        "**6.2 Importance of Balanced Data**\n",
        "\n",
        "Balancing the dataset using SMOTE was crucial for improving the performance of the models, as it ensured that the models were trained on an equal number of examples from both classes.\n",
        "\n",
        "**6.3 Future Work**\n",
        "\n",
        "\n",
        "Improving the model by exploring other algorithms and hyperparameter tuning.\n",
        "Integrating the API with a customer management system for real-time predictions.\n",
        "Using real-world data for more accurate predictions."
      ],
      "metadata": {
        "id": "WsQRxXQm5ZWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. API Deployment**\n",
        "\n",
        "**7.1 Save the Model**"
      ],
      "metadata": {
        "id": "Bq_CfA836Qc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Random Forest model\n",
        "joblib.dump(rf, 'random_forest_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46mYeV7M6Ub-",
        "outputId": "7c4b1e86-fbc1-4d0e-8b26-82703bd28657"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of customer churn prediction, common features might include:\n",
        "\n",
        "Demographic Information: Age, gender, income, etc.\n",
        "Account Information: Tenure, contract type, billing method, etc.\n",
        "Service Information: Number of services subscribed to, types of services, usage patterns, etc.\n",
        "Customer Support Interactions: Number of support calls, issues resolved, etc.\n",
        "Payment Information: Payment method, last payment amount, etc.\n",
        "To provide a more concrete example, let's assume we have a dataset with the following features for predicting customer churn:\n",
        "\n",
        "Tenure: Number of months the customer has been with the company.\n",
        "Monthly Charges: The amount charged to the customer monthly.\n",
        "Total Charges: The total amount charged to the customer.\n",
        "We can use these features in our Streamlit application for customer churn prediction.\n",
        "\n",
        "Streamlit App Code with Relevant Features\n",
        "Here's the updated Streamlit app code with these example features:\n"
      ],
      "metadata": {
        "id": "RWJN0-CQp-P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tr68TaawGe0",
        "outputId": "136fd020-5f01-4e8d-864e-3ed4685e9bb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.36.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the synthetic dataset\n",
        "df_synthetic = pd.read_csv('synthetic_dataset.csv')\n",
        "\n",
        "# Display the first few rows and column names to verify\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df_synthetic.head())\n",
        "\n",
        "print(\"\\nColumn names in the dataset:\")\n",
        "print(df_synthetic.columns.tolist())\n"
      ],
      "metadata": {
        "id": "0ff1u7ZoB1Go",
        "outputId": "63b74703-300a-4726-f628-a4b250762b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "0  -0.429244  -2.211862   0.189756   0.588553   0.820374  -0.180392   \n",
            "1  -0.045512  -2.084113  -3.189191  -0.424236  -2.472718   0.508269   \n",
            "2   0.252195   1.617045   1.565132  -1.970309   2.048682   0.509295   \n",
            "3   1.725694  -0.516117   2.210866   0.121844   2.667175  -1.059212   \n",
            "4  -0.749416   1.106232  -0.664455   0.337766  -0.054664   0.552905   \n",
            "\n",
            "   feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
            "0  -1.150654   1.471709   0.701585  -0.833474  ...    0.702818   -0.225999   \n",
            "1  -2.850971   0.911854   0.472527  -1.210002  ...   -2.126279    1.908717   \n",
            "2  -0.238676   1.445465   0.673300  -0.529416  ...    1.758406   -1.076195   \n",
            "3   0.107509   1.527901   0.705332  -0.442889  ...    2.289787   -1.482342   \n",
            "4  -1.497095   1.233776   0.597581  -0.871460  ...   -0.048795    0.320768   \n",
            "\n",
            "   feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
            "0    1.533434    1.372848    0.673782    0.742188    0.944224   -0.266652   \n",
            "1    1.724697    3.926238    0.736881    3.447367    2.551819    0.287329   \n",
            "2   -0.770425   -0.616071    0.528587   -0.516697    0.107330    0.184859   \n",
            "3    2.124556   -0.500261    0.504980   -1.048914   -0.217528   -0.179620   \n",
            "4    0.200699   -0.936592    0.644399    1.366224    1.281389   -0.344477   \n",
            "\n",
            "   feature_19  Churn  \n",
            "0    1.401753      0  \n",
            "1   -0.842841      0  \n",
            "2    2.090307      0  \n",
            "3    2.497511      0  \n",
            "4    0.748926      0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Column names in the dataset:\n",
            "['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'Churn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# Define the Streamlit app\n",
        "st.title('Customer Churn Prediction')\n",
        "\n",
        "# Input fields for customer features\n",
        "gender = st.selectbox('Gender', ['Male', 'Female'])\n",
        "SeniorCitizen = st.selectbox('Senior Citizen', [0, 1])\n",
        "Partner = st.selectbox('Partner', ['Yes', 'No'])\n",
        "Dependents = st.selectbox('Dependents', ['Yes', 'No'])\n",
        "tenure = st.number_input('Tenure (months)', min_value=0)\n",
        "PhoneService = st.selectbox('Phone Service', ['Yes', 'No'])\n",
        "MultipleLines = st.selectbox('Multiple Lines', ['Yes', 'No', 'No phone service'])\n",
        "InternetService = st.selectbox('Internet Service', ['DSL', 'Fiber optic', 'No'])\n",
        "OnlineSecurity = st.selectbox('Online Security', ['Yes', 'No', 'No internet service'])\n",
        "OnlineBackup = st.selectbox('Online Backup', ['Yes', 'No', 'No internet service'])\n",
        "DeviceProtection = st.selectbox('Device Protection', ['Yes', 'No', 'No internet service'])\n",
        "TechSupport = st.selectbox('Tech Support', ['Yes', 'No', 'No internet service'])\n",
        "StreamingTV = st.selectbox('Streaming TV', ['Yes', 'No', 'No internet service'])\n",
        "StreamingMovies = st.selectbox('Streaming Movies', ['Yes', 'No', 'No internet service'])\n",
        "Contract = st.selectbox('Contract', ['Month-to-month', 'One year', 'Two year'])\n",
        "PaperlessBilling = st.selectbox('Paperless Billing', ['Yes', 'No'])\n",
        "PaymentMethod = st.selectbox('Payment Method', ['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'])\n",
        "MonthlyCharges = st.number_input('Monthly Charges ($)', min_value=0.0)\n",
        "TotalCharges = st.number_input('Total Charges ($)', min_value=0.0)\n",
        "\n",
        "# Function to create tenure group based on tenure\n",
        "def tenure_group(tenure):\n",
        "    if tenure <= 12:\n",
        "        return '0-12 months'\n",
        "    elif tenure <= 24:\n",
        "        return '12-24 months'\n",
        "    elif tenure <= 36:\n",
        "        return '24-36 months'\n",
        "    elif tenure <= 48:\n",
        "        return '36-48 months'\n",
        "    elif tenure <= 60:\n",
        "        return '48-60 months'\n",
        "    else:\n",
        "        return '60+ months'\n",
        "\n",
        "tenure_group_value = tenure_group(tenure)\n",
        "\n",
        "# Create a DataFrame for the input features\n",
        "input_data = pd.DataFrame({\n",
        "    'gender': [gender],\n",
        "    'SeniorCitizen': [SeniorCitizen],\n",
        "    'Partner': [Partner],\n",
        "    'Dependents': [Dependents],\n",
        "    'tenure': [tenure],\n",
        "    'PhoneService': [PhoneService],\n",
        "    'MultipleLines': [MultipleLines],\n",
        "    'InternetService': [InternetService],\n",
        "    'OnlineSecurity': [OnlineSecurity],\n",
        "    'OnlineBackup': [OnlineBackup],\n",
        "    'DeviceProtection': [DeviceProtection],\n",
        "    'TechSupport': [TechSupport],\n",
        "    'StreamingTV': [StreamingTV],\n",
        "    'StreamingMovies': [StreamingMovies],\n",
        "    'Contract': [Contract],\n",
        "    'PaperlessBilling': [PaperlessBilling],\n",
        "    'PaymentMethod': [PaymentMethod],\n",
        "    'MonthlyCharges': [MonthlyCharges],\n",
        "    'TotalCharges': [TotalCharges],\n",
        "    'tenure_group': [tenure_group_value]\n",
        "})\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "input_data['gender'] = input_data['gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
        "input_data['Partner'] = input_data['Partner'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['Dependents'] = input_data['Dependents'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['PhoneService'] = input_data['PhoneService'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['MultipleLines'] = input_data['MultipleLines'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['InternetService'] = input_data['InternetService'].apply(lambda x: 2 if x == 'Fiber optic' else (1 if x == 'DSL' else 0))\n",
        "input_data['OnlineSecurity'] = input_data['OnlineSecurity'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['OnlineBackup'] = input_data['OnlineBackup'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['DeviceProtection'] = input_data['DeviceProtection'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['TechSupport'] = input_data['TechSupport'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['StreamingTV'] = input_data['StreamingTV'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['StreamingMovies'] = input_data['StreamingMovies'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['Contract'] = input_data['Contract'].apply(lambda x: 2 if x == 'Two year' else (1 if x == 'One year' else 0))\n",
        "input_data['PaperlessBilling'] = input_data['PaperlessBilling'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['PaymentMethod'] = input_data['PaymentMethod'].apply(lambda x: 3 if x == 'Electronic check' else (2 if x == 'Mailed check' else (1 if x == 'Bank transfer (automatic)' else 0)))\n",
        "input_data['tenure_group'] = input_data['tenure_group'].apply(lambda x: {'0-12 months': 1, '12-24 months': 2, '24-36 months': 3, '36-48 months': 4, '48-60 months': 5, '60+ months': 6}[x])\n",
        "\n",
        "# Debug line to check the shape and columns of the input data\n",
        "st.write(\"Features provided for prediction:\", input_data.columns.tolist(), input_data.shape)\n",
        "\n",
        "# Predict churn\n",
        "if st.button('Predict Churn'):\n",
        "    prediction = model.predict(input_data)\n",
        "    if prediction[0] == 1:\n",
        "        st.write('The customer is likely to churn.')\n",
        "    else:\n",
        "        st.write('The customer is not likely to churn.')\n"
      ],
      "metadata": {
        "id": "ULOOe-vo-xxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c72b771-eb05-419e-9aa0-234f319ccc1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-21 23:23:58.251 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-06-21 23:23:58.253 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Streamlit and pyngrok\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok -q\n",
        "\n",
        "# Write the Streamlit application to a file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# Define the Streamlit app\n",
        "st.title('Customer Churn Prediction')\n",
        "\n",
        "# Input fields for customer features\n",
        "customerID = st.text_input('Customer ID')\n",
        "gender = st.selectbox('Gender', ['Male', 'Female'])\n",
        "SeniorCitizen = st.selectbox('Senior Citizen', [0, 1])\n",
        "Partner = st.selectbox('Partner', ['Yes', 'No'])\n",
        "Dependents = st.selectbox('Dependents', ['Yes', 'No'])\n",
        "tenure = st.number_input('Tenure (months)', min_value=0)\n",
        "PhoneService = st.selectbox('Phone Service', ['Yes', 'No'])\n",
        "MultipleLines = st.selectbox('Multiple Lines', ['Yes', 'No', 'No phone service'])\n",
        "InternetService = st.selectbox('Internet Service', ['DSL', 'Fiber optic', 'No'])\n",
        "OnlineSecurity = st.selectbox('Online Security', ['Yes', 'No', 'No internet service'])\n",
        "OnlineBackup = st.selectbox('Online Backup', ['Yes', 'No', 'No internet service'])\n",
        "DeviceProtection = st.selectbox('Device Protection', ['Yes', 'No', 'No internet service'])\n",
        "TechSupport = st.selectbox('Tech Support', ['Yes', 'No', 'No internet service'])\n",
        "StreamingTV = st.selectbox('Streaming TV', ['Yes', 'No', 'No internet service'])\n",
        "StreamingMovies = st.selectbox('Streaming Movies', ['Yes', 'No', 'No internet service'])\n",
        "Contract = st.selectbox('Contract', ['Month-to-month', 'One year', 'Two year'])\n",
        "PaperlessBilling = st.selectbox('Paperless Billing', ['Yes', 'No'])\n",
        "PaymentMethod = st.selectbox('Payment Method', ['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'])\n",
        "MonthlyCharges = st.number_input('Monthly Charges ($)', min_value=0.0)\n",
        "TotalCharges = st.number_input('Total Charges ($)', min_value=0.0)\n",
        "\n",
        "# Function to create tenure group based on tenure\n",
        "def tenure_group(tenure):\n",
        "    if tenure <= 12:\n",
        "        return '0-12 months'\n",
        "    elif tenure <= 24:\n",
        "        return '12-24 months'\n",
        "    elif tenure <= 36:\n",
        "        return '24-36 months'\n",
        "    elif tenure <= 48:\n",
        "        return '36-48 months'\n",
        "    elif tenure <= 60:\n",
        "        return '48-60 months'\n",
        "    else:\n",
        "        return '60+ months'\n",
        "\n",
        "tenure_group_value = tenure_group(tenure)\n",
        "\n",
        "# Create a DataFrame for the input features\n",
        "input_data = pd.DataFrame({\n",
        "    'gender': [gender],\n",
        "    'SeniorCitizen': [SeniorCitizen],\n",
        "    'Partner': [Partner],\n",
        "    'Dependents': [Dependents],\n",
        "    'tenure': [tenure],\n",
        "    'PhoneService': [PhoneService],\n",
        "    'MultipleLines': [MultipleLines],\n",
        "    'InternetService': [InternetService],\n",
        "    'OnlineSecurity': [OnlineSecurity],\n",
        "    'OnlineBackup': [OnlineBackup],\n",
        "    'DeviceProtection': [DeviceProtection],\n",
        "    'TechSupport': [TechSupport],\n",
        "    'StreamingTV': [StreamingTV],\n",
        "    'StreamingMovies': [StreamingMovies],\n",
        "    'Contract': [Contract],\n",
        "    'PaperlessBilling': [PaperlessBilling],\n",
        "    'PaymentMethod': [PaymentMethod],\n",
        "    'MonthlyCharges': [MonthlyCharges],\n",
        "    'TotalCharges': [TotalCharges],\n",
        "    'tenure_group': [tenure_group_value]\n",
        "})\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "input_data['gender'] = input_data['gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
        "input_data['Partner'] = input_data['Partner'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['Dependents'] = input_data['Dependents'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['PhoneService'] = input_data['PhoneService'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['MultipleLines'] = input_data['MultipleLines'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['InternetService'] = input_data['InternetService'].apply(lambda x: 2 if x == 'Fiber optic' else (1 if x == 'DSL' else 0))\n",
        "input_data['OnlineSecurity'] = input_data['OnlineSecurity'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['OnlineBackup'] = input_data['OnlineBackup'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['DeviceProtection'] = input_data['DeviceProtection'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['TechSupport'] = input_data['TechSupport'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['StreamingTV'] = input_data['StreamingTV'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['StreamingMovies'] = input_data['StreamingMovies'].apply(lambda x: 2 if x == 'Yes' else (1 if x == 'No' else 0))\n",
        "input_data['Contract'] = input_data['Contract'].apply(lambda x: 2 if x == 'Two year' else (1 if x == 'One year' else 0))\n",
        "input_data['PaperlessBilling'] = input_data['PaperlessBilling'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "input_data['PaymentMethod'] = input_data['PaymentMethod'].apply(lambda x: 3 if x == 'Electronic check' else (2 if x == 'Mailed check' else (1 if x == 'Bank transfer (automatic)' else 0)))\n",
        "input_data['tenure_group'] = input_data['tenure_group'].apply(lambda x: {'0-12 months': 1, '12-24 months': 2, '24-36 months': 3, '36-48 months': 4, '48-60 months': 5, '60+ months': 6}[x])\n",
        "\n",
        "# Debug line to check the shape and columns of the input data\n",
        "st.write(\"Features provided for prediction:\", input_data.columns.tolist(), input_data.shape)\n",
        "\n",
        "# Predict churn\n",
        "if st.button('Predict Churn'):\n",
        "    prediction = model.predict(input_data)\n",
        "    if prediction[0] == 1:\n",
        "        st.write('The customer is likely to churn.')\n",
        "    else:\n",
        "        st.write('The customer is not likely to churn.')\n",
        "    \"\"\")\n",
        "\n",
        "# Authenticate ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok authtoken\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py\n"
      ],
      "metadata": {
        "id": "SpaoHjmUCit6",
        "outputId": "ab7429ba-b634-4ef7-bdf0-8243f4d8c86f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://a652-34-16-141-221.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.141.221:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}
